{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploration des données - DynamicEarthNet**\n",
    "## **1. Présentation du contexte et du jeu de données**\n",
    "\n",
    "Dans ce projet, l’objectif principal est la réalisation d’une **segmentation sémantique spatiale** à partir d’images satellites issues de la base de données **DynamicEarthNet**. Cette dernière se compose d’images satellites multispectrales (RGB + proche infrarouge) annotées manuellement pour différents types de couverture terrestre.\n",
    "\n",
    "Le jeu de données se caractérise par :\n",
    "- **Résolution spatiale** : 3 mètres par pixel (chaque image fait 1024x1024 pixels).\n",
    "- **Annotations manuelles précises**, pixel par pixel, classifiant la couverture terrestre en plusieurs classes sémantiques clairement définies.\n",
    "\n",
    "> Source : *DynamicEarthNet Paper, Toker et al. 2022*.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première étape de notre projet à donc été de visualiser et de prendre en main la données. Pour cela deux module ont été crée : [sat_image_reader](src/sat_image_reader.py) et [classes_reader](src/classes_reader.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **2. Classes sémantiques utilisées dans l'exploration**\n",
    "\n",
    "Le jeu de données DynamicEarthNet comporte au total **7 classes sémantiques** différentes :\n",
    "\n",
    "1. **Impervious Surface** – Surfaces imperméables (routes, bâtiments).\n",
    "2. **Forest & Other Vegetation** – Forêt et autres végétations.\n",
    "3. **Soil** – Sols nus ou terres agricoles non cultivées.\n",
    "4. **Agriculture** – Zones agricoles cultivées.\n",
    "5. **Wetlands** – Zones humides.\n",
    "6. **Water** – Plans d’eau.\n",
    "7. **Snow & Ice** – Neige et glace (rare, non incluse dans cette analyse).\n",
    "\n",
    "Dans la zone étudiée (**10N-123W-45N**), seules **3 classes principales** sont présentes :\n",
    "\n",
    "- **Impervious Surface (bande 1)**\n",
    "- **Forest and Other Vegetation (bande 3)**\n",
    "- **Soil (bande 5)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **3. Approche méthodologique d’exploration**\n",
    "\n",
    "### **a. Exploration initiale des fichiers raster (.tif)**\n",
    "\n",
    "L’analyse initiale a consisté à examiner les fichiers raster pour :\n",
    "- Lire les métadonnées (dimensions, nombre de bandes, résolution).\n",
    "- Visualiser les bandes individuellement :\n",
    "  - Classification binaire (valeurs 0 ou 255).\n",
    "  - Identification des pixels appartenant simultanément à plusieurs classes.\n",
    "- Générer des histogrammes confirmant la distribution binaire des pixels.\n",
    "\n",
    "### **b. Validation spatiale avec les fichiers vectoriels (.geojson)**\n",
    "\n",
    "Les fichiers **GeoJSON** ont été utilisés pour valider spatialement les annotations :\n",
    "- Chargement et visualisation des contours géographiques de chaque classe.\n",
    "- Superposition des géométries vectorielles sur les images raster.\n",
    "- Confirmation de la cohérence et de la précision des annotations.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **4. Analyse complémentaire : NDVI**\n",
    "\n",
    "Un calcul de l’**indice de végétation NDVI** a été effectué à partir des bandes rouge et proche infrarouge :\n",
    "\n",
    "- **Objectif** : Vérifier la correspondance entre le NDVI et les annotations de végétation.\n",
    "- **Résultats** :\n",
    "  - NDVI élevé (> 0.5) → correspondance forte avec la classe **Forest & Other Vegetation**.\n",
    "  - Confirmation de la pertinence du NDVI comme attribut supplémentaire pour améliorer la segmentation.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **5. Analyse de la qualité des données (PF-QA)**\n",
    "\n",
    "L’étude des fichiers **PF-QA (Planet Fusion Quality Assurance)** a permis de :\n",
    "- Identifier les pixels basés sur des observations satellites directes vs interpolées.\n",
    "- Vérifier la cohérence spatiale des annotations pour garantir la fiabilité des données d’apprentissage.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **6. Synthèse des résultats de l’exploration**\n",
    "\n",
    "L’exploration des données DynamicEarthNet a permis de dégager les éléments suivants :\n",
    "- **Trois classes principales retenues** : Impervious Surface, Forest & Other Vegetation, et Soil.\n",
    "- Les annotations raster sont **clairement binaires**, facilitant l’apprentissage supervisé.\n",
    "- Validation rigoureuse des annotations grâce aux données vectorielles.\n",
    "- **Le NDVI est un bon indicateur** pour compléter la segmentation des zones végétalisées.\n",
    "- **Les données PF-QA doivent être prises en compte** pour éviter d’entraîner le modèle sur des pixels interpolés.\n",
    "\n",
    "Ces observations serviront de **base pour l’entraînement d’un modèle de segmentation** précis et fiable à partir des images satellites de DynamicEarthNet."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
