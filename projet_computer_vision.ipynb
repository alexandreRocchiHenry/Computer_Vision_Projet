{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploration des donn√©es - DynamicEarthNet**\n",
    "## **1. Pr√©sentation du contexte et du jeu de donn√©es**\n",
    "\n",
    "Dans ce projet, l‚Äôobjectif principal est la r√©alisation d‚Äôune **segmentation s√©mantique spatiale** √† partir d‚Äôimages satellites issues de la base de donn√©es **DynamicEarthNet**. Cette derni√®re se compose d‚Äôimages satellites multispectrales (RGB + proche infrarouge) annot√©es manuellement pour diff√©rents types de couverture terrestre.\n",
    "\n",
    "Le jeu de donn√©es se caract√©rise par :\n",
    "- **R√©solution spatiale** : 3 m√®tres par pixel (chaque image fait 1024x1024 pixels).\n",
    "- **Annotations manuelles pr√©cises**, pixel par pixel, classifiant la couverture terrestre en plusieurs classes s√©mantiques clairement d√©finies.\n",
    "\n",
    "> Source : *DynamicEarthNet Paper, Toker et al. 2022*.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La premi√®re √©tape de notre projet √† donc √©t√© de visualiser et de prendre en main la donn√©es. Pour cela deux module ont √©t√© cr√©e : [sat_image_reader](src/sat_image_reader.py) et [classes_reader](src/classes_reader.py).\n",
    "\n",
    "Gr√¢√ße √† cela, nous avons pu analyser diverses images et les prendre en main dans un [notebook](exploration_donn√©es_Alexandre.ipynb).\n",
    "Nous avons alors pu comprendre les diverses classes de DynamicEarthNet, leur impl√©mentation (sous 8 bandes √† valeurs 0 ou 255 si la classe est pr√©sente) et l'√©volution temporelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **2. Classes s√©mantiques utilis√©es dans l'exploration**\n",
    "\n",
    "Le jeu de donn√©es DynamicEarthNet comporte au total **7 classes s√©mantiques** diff√©rentes :\n",
    "\n",
    "1. **Impervious Surface** ‚Äì Surfaces imperm√©ables (routes, b√¢timents).\n",
    "2. **Forest & Other Vegetation** ‚Äì For√™t et autres v√©g√©tations.\n",
    "3. **Soil** ‚Äì Sols nus ou terres agricoles non cultiv√©es.\n",
    "4. **Agriculture** ‚Äì Zones agricoles cultiv√©es.\n",
    "5. **Wetlands** ‚Äì Zones humides.\n",
    "6. **Water** ‚Äì Plans d‚Äôeau.\n",
    "7. **Snow & Ice** ‚Äì Neige et glace (rare).\n",
    "\n",
    "Mais elles ne sont pas forc√®ment toutes pr√©sente √† chaque fois : par exemple dans une zone √©tudi√©e du notebook (**10N-123W-45N**), seules **3 classes principales** sont pr√©sentes :\n",
    "\n",
    "- **Impervious Surface (bande 1)**\n",
    "- **Forest and Other Vegetation (bande 3)**\n",
    "- **Soil (bande 5)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons donc pris cela en compte lors de la cr√©ation de notre [dataloader](src/dataloader.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **3. Approche m√©thodologique d‚Äôexploration**\n",
    "\n",
    "### **a. Exploration initiale des fichiers raster (.tif)**\n",
    "\n",
    "L‚Äôanalyse initiale a consist√© √† examiner les fichiers raster pour :\n",
    "- Lire les m√©tadonn√©es (dimensions, nombre de bandes, r√©solution).\n",
    "- Visualiser les bandes individuellement :\n",
    "  - Classification binaire (valeurs 0 ou 255).\n",
    "  - Identification des pixels appartenant simultan√©ment √† plusieurs classes.\n",
    "- G√©n√©rer des histogrammes confirmant la distribution binaire des pixels.\n",
    "\n",
    "### **b. Validation spatiale avec les fichiers vectoriels (.geojson)**\n",
    "\n",
    "Les fichiers **GeoJSON** ont √©t√© utilis√©s pour valider spatialement les annotations :\n",
    "- Chargement et visualisation des contours g√©ographiques de chaque classe.\n",
    "- Superposition des g√©om√©tries vectorielles sur les images raster.\n",
    "- Confirmation de la coh√©rence et de la pr√©cision des annotations.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## **4. Analyse de la qualit√© des donn√©es (PF-QA)**\n",
    "\n",
    "L‚Äô√©tude des fichiers **PF-QA (Planet Fusion Quality Assurance)** a permis de :\n",
    "- Identifier les pixels bas√©s sur des observations satellites directes vs interpol√©es.\n",
    "- V√©rifier la coh√©rence spatiale des annotations pour garantir la fiabilit√© des donn√©es d‚Äôapprentissage.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploration des fichiers et structuration des donn√©es**\n",
    "\n",
    "\n",
    "## **1. Organisation et exploration des fichiers**\n",
    "Le chemin principal des donn√©es est d√©fini par `PATH_DATA`, qui contient :\n",
    "- Les images satellites **Planet Fusion** (`planet.10N/planet/10N/`).\n",
    "- Les labels annot√©s (`labels/labels/` et `dynamicearthnet_test_labels`).\n",
    "\n",
    "L‚Äôexploration initiale a permis :\n",
    "- üìÇ **D‚Äôidentifier les fichiers et r√©pertoires disponibles**.\n",
    "- üè∑Ô∏è **De compter et comparer les labels d‚Äôentra√Ænement et de test**.\n",
    "- üìç **D‚Äôafficher les sous-dossiers Planet contenant les images TIFF** pour une organisation claire des donn√©es.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Construction des DataFrames de labels et images**\n",
    "L‚Äôorganisation des labels a √©t√© syst√©matis√©e en DataFrames `df_labels_train` et `df_labels_test` :\n",
    "- **Extraction des cl√©s d‚Äôidentification** pour assurer la correspondance avec les images satellites.\n",
    "- **Identification des labels d‚Äôentra√Ænement et de test**.\n",
    "- **Cr√©ation d‚Äôun chemin structur√© pour chaque label**.\n",
    "\n",
    "Les images satellites ont √©t√© associ√©es aux labels via une fusion avec `df_planet`, permettant de structurer les correspondances entre annotations et images sources.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Localisation g√©ographique des images**\n",
    "L‚Äôanalyse de la **localisation des images satellites** a √©t√© effectu√©e en croisant leurs coordonn√©es avec une base de donn√©es mondiale des pays (`ne_110m_admin_0_countries.shp`).\n",
    "\n",
    "- üåç **Transformation des coordonn√©es vers EPSG:4326** (longitude/latitude).\n",
    "- üó∫Ô∏è **D√©tection du pays et du continent** associ√© √† chaque image satellite.\n",
    "- üîó **Association des informations g√©ographiques aux m√©tadonn√©es des images**.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. V√©rification de l‚Äôalignement des images satellites**\n",
    "Un contr√¥le d‚Äôalignement des images (`ImageAlignementCheck`) a √©t√© effectu√© pour s‚Äôassurer de leur qualit√©, nous avions initialement pr√©vu de faire avec le suivi temporelle mais nous avons ensuite abandonn√© cette id√©e :\n",
    "- üìè **Analyse des d√©calages moyens et maximaux entre images successives**.\n",
    "- ‚ùå **Identification des images mal align√©es** afin de les exclure du futur entra√Ænement du mod√®le.\n",
    "\n",
    "Les r√©sultats ont √©t√© stock√©s dans `df_results.csv` et int√©gr√©s dans `df_merged_extended` pour une meilleure gestion des images.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "L‚Äôensemble de ces √©tapes garantit une **base de donn√©es robuste et de haute qualit√©** pour l'entra√Ænement du **r√©seau de neurones de segmentation spatiale**. üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
